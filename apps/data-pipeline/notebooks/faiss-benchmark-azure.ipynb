{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran on Standard_D4ds_v5 colocated with the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7161cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import os\n",
    "\n",
    "def download_azure_files(account_name, account_key, container_name, prefix):\n",
    "    \"\"\"\n",
    "    Download files from Azure Blob Storage that match a specific prefix pattern.\n",
    "    \n",
    "    Args:\n",
    "        account_name (str): Azure Storage account name\n",
    "        account_key (str): Azure Storage account key\n",
    "        container_name (str): Container name\n",
    "        prefix (str): Prefix pattern to match files\n",
    "    \"\"\"\n",
    "    # Create the connection string\n",
    "    connect_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "    \n",
    "    # Create the BlobServiceClient\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "    \n",
    "    # Get the container client\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    \n",
    "    # List all blobs in the container that match the prefix\n",
    "    blobs = container_client.list_blobs(name_starts_with=prefix)\n",
    "    \n",
    "    # Create local directory if it doesn't exist\n",
    "    os.makedirs('downloaded_files', exist_ok=True)\n",
    "    \n",
    "    # Download each matching blob\n",
    "    for blob in blobs:\n",
    "        print(f\"Downloading: {blob.name}\")\n",
    "        \n",
    "        # Get blob client\n",
    "        blob_client = container_client.get_blob_client(blob.name)\n",
    "        \n",
    "        # Create the local file path\n",
    "        local_file_name = os.path.join('downloaded_files', os.path.basename(blob.name))\n",
    "        \n",
    "        # Download the blob\n",
    "        with open(local_file_name, \"wb\") as file:\n",
    "            data = blob_client.download_blob()\n",
    "            file.write(data.readall())\n",
    "            \n",
    "        print(f\"Successfully downloaded to: {local_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Environment variables for Azure Storage\n",
    "account_name = AZURE_STORAGE_ACCOUNT_NAME\n",
    "account_key = AZURE_STORAGE_ACCOUNT_KEY\n",
    "container_name = AZURE_STORAGE_CONTAINER_NAME\n",
    "\n",
    "# Prefix pattern to match\n",
    "prefix = \"dagster/speculatives_substantiation/\"\n",
    "\n",
    "# Download the files\n",
    "download_azure_files(account_name, account_key, container_name, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import faiss\n",
    "import random\n",
    "\n",
    "# Cell 1: Load Data\n",
    "# Load the Parquet file\n",
    "file_path = \"downloaded_files/cm0i27jdj0000aqpa73ghpcxf.snappy\"  # Update with your file path\n",
    "df = pl.read_parquet(file_path)\n",
    "print(f\"Loaded dataframe with shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Convert embeddings to numpy array\n",
    "embeddings = np.stack(df['embedding'].to_numpy()).astype(np.float32)\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "\n",
    "# Initialize FAISS index with Inner Product (for cosine similarity with normalized vectors)\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "# Add normalized vectors to the index\n",
    "index.add(embeddings)\n",
    "print(f\"Built FAISS index with {index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45108203",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Select and normalize random query vector\n",
    "random_idx = random.randint(0, len(embeddings) - 1)\n",
    "query_vector = embeddings[random_idx].reshape(1, -1).copy()  # Make a copy to avoid modifying original\n",
    "faiss.normalize_L2(query_vector)\n",
    "print(f\"Using random vector at index {random_idx} as query\")\n",
    "\n",
    "# Perform search\n",
    "k = 30  # Number of nearest neighbors\n",
    "similarities, indices = index.search(query_vector, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e019f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "print(f\"Total runtime: {runtime:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}